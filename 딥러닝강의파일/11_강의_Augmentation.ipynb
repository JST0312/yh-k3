{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tk_swS0qa5a"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGxCD4mGHHjG"
      },
      "source": [
        "Cats v Dogs 로 다음처럼 모델링 하고, 학습시켜본다.\n",
        "\n",
        "4 convolutional layers with 32, 64, 128 and 128 convolutions\n",
        "\n",
        "train for 100 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb81GvNov-Tg"
      },
      "source": [
        "### 데이터 제너레이터를 통해 이미지를 증강한다.\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "```\n",
        "\n",
        "* rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures.\n",
        "* width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally.\n",
        "* shear_range is for randomly applying shearing transformations.\n",
        "* zoom_range is for randomly zooming inside pictures.\n",
        "* horizontal_flip is for randomly flipping half of the images horizontally. This is relevant when there are no assumptions of horizontal assymmetry (e.g. real-world pictures).\n",
        "* fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOEgKH-dMtPS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UK7_Fflgv8YC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0136278f-e63a-4ce4-8b2e-e5e1de44adaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-30 06:45:01--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 172.253.123.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   154MB/s    in 0.4s    \n",
            "\n",
            "2022-12-30 06:45:01 (154 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UVjhcyXKrXc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m0P8YhgtpUTV"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OwDXn6L9pT3U"
      },
      "outputs": [],
      "source": [
        "file = zipfile.ZipFile('/tmp/cats_and_dogs_filtered.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file.extractall('/tmp')"
      ],
      "metadata": {
        "id": "qzJEYV04fPLw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YcuWbCKSrXZZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nZrHqWggrYeC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MyQ2yfKxpWbN"
      },
      "outputs": [],
      "source": [
        "base_dir = '/tmp/cats_and_dogs_filtered'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4sfdvx8YpXO5"
      },
      "outputs": [],
      "source": [
        "train_dir = '/tmp/cats_and_dogs_filtered/train'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = '/tmp/cats_and_dogs_filtered/validation'"
      ],
      "metadata": {
        "id": "7ggg54vxgTdu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ioOKAk8UrYbD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fTb_R4b9rYX-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qvfZg3LQbD-5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G1HHc5s8qKSY"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add( Conv2D(16, (3,3) , activation='relu' , input_shape=(150,150,3)  ) )\n",
        "  model.add( MaxPooling2D( (2,2) , 2 ) )\n",
        "  model.add( Conv2D(32, (3,3), activation='relu'))\n",
        "  model.add( MaxPooling2D( (2,2) , 2 ) )\n",
        "  model.add( Conv2D(64, (3,3) , activation='relu'))\n",
        "  model.add( MaxPooling2D( (2,2) , 2 ) )\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512, 'relu'))\n",
        "  model.add(Dense(1, 'sigmoid'))\n",
        "  \n",
        "  model.compile('rmsprop', 'binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "nYph50IzrXVP"
      },
      "outputs": [],
      "source": [
        "model = build_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q7PTJDPCrXR1"
      },
      "outputs": [],
      "source": [
        "# 이미지 데이터를 증강하여, 학습을 시키자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iAjQxTIEMy6-"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PHXtne_LrdxC"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.0, rotation_range= 30, \n",
        "                                   width_shift_range= 0.4, \n",
        "                                   height_shift_range= 0.2, \n",
        "                                   shear_range= 0.3,\n",
        "                                   zoom_range= 0.5, \n",
        "                                   horizontal_flip= True )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FvANuxL3rdt4"
      },
      "outputs": [],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1/255.0 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "B33g8y5nrdq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e6c417-e8e9-4d39-e179-db89421d09ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir, (150,150) ,\n",
        "                                  class_mode='binary', \n",
        "                                  batch_size = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "X--1_5PQrdoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9746f1fb-4cad-4f59-ad82-1640725606e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator = test_datagen.flow_from_directory(test_dir, (150, 150), \n",
        "                                        class_mode='binary',\n",
        "                                        batch_size = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-3_wjHDzrdk8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3056827-a7e1-4b4d-b5f0-2dc24039b685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "100/100 [==============================] - 79s 778ms/step - loss: 0.8242 - accuracy: 0.5385 - val_loss: 0.6816 - val_accuracy: 0.5170\n",
            "Epoch 2/15\n",
            "100/100 [==============================] - 78s 782ms/step - loss: 0.6889 - accuracy: 0.5645 - val_loss: 0.6394 - val_accuracy: 0.6070\n",
            "Epoch 3/15\n",
            "100/100 [==============================] - 76s 754ms/step - loss: 0.6764 - accuracy: 0.5805 - val_loss: 0.6563 - val_accuracy: 0.5500\n",
            "Epoch 4/15\n",
            "100/100 [==============================] - 76s 762ms/step - loss: 0.6678 - accuracy: 0.6010 - val_loss: 0.6309 - val_accuracy: 0.6370\n",
            "Epoch 5/15\n",
            "100/100 [==============================] - 80s 803ms/step - loss: 0.6580 - accuracy: 0.6400 - val_loss: 0.6227 - val_accuracy: 0.6530\n",
            "Epoch 6/15\n",
            "100/100 [==============================] - 77s 772ms/step - loss: 0.6372 - accuracy: 0.6255 - val_loss: 0.5985 - val_accuracy: 0.6610\n",
            "Epoch 7/15\n",
            "100/100 [==============================] - 77s 771ms/step - loss: 0.6530 - accuracy: 0.6085 - val_loss: 0.6377 - val_accuracy: 0.6670\n",
            "Epoch 8/15\n",
            "100/100 [==============================] - 80s 801ms/step - loss: 0.6405 - accuracy: 0.6430 - val_loss: 0.5923 - val_accuracy: 0.6840\n",
            "Epoch 9/15\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.6377 - accuracy: 0.6485 - val_loss: 0.5991 - val_accuracy: 0.6710\n",
            "Epoch 10/15\n",
            "100/100 [==============================] - 77s 772ms/step - loss: 0.6274 - accuracy: 0.6440 - val_loss: 0.5991 - val_accuracy: 0.6790\n",
            "Epoch 11/15\n",
            "100/100 [==============================] - 80s 801ms/step - loss: 0.6143 - accuracy: 0.6580 - val_loss: 0.6297 - val_accuracy: 0.6420\n",
            "Epoch 12/15\n",
            "100/100 [==============================] - 77s 767ms/step - loss: 0.6090 - accuracy: 0.6625 - val_loss: 0.5832 - val_accuracy: 0.6900\n",
            "Epoch 13/15\n",
            "100/100 [==============================] - 77s 770ms/step - loss: 0.6124 - accuracy: 0.6640 - val_loss: 0.5574 - val_accuracy: 0.7050\n",
            "Epoch 14/15\n",
            "100/100 [==============================] - 80s 797ms/step - loss: 0.6089 - accuracy: 0.6660 - val_loss: 0.5471 - val_accuracy: 0.7260\n",
            "Epoch 15/15\n",
            "100/100 [==============================] - 77s 769ms/step - loss: 0.6009 - accuracy: 0.6730 - val_loss: 0.5836 - val_accuracy: 0.6720\n"
          ]
        }
      ],
      "source": [
        "epoch_history = model.fit(train_generator, epochs=15, \n",
        "                          validation_data = (test_generator) , \n",
        "                          steps_per_epoch= 100 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7urTPZ_wrhpx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2BMOKhLKrhmz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sXi2GKuerhj-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-kOMVNzmrhhK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_5RBT0jzrheL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO30htPcrnMk"
      },
      "source": [
        "### 차트 그려보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3v8w6N0TrnMl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gb5jP74grojm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "G4fHUXQ4rogZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FzZ3erTirodX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "67rHzXJdroaj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_oU0CuHCroXw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "P_E7gAkTroUg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}